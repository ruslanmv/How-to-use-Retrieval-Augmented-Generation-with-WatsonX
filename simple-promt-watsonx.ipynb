{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "676d8ed6-9932-4ee6-96f0-92a7ba81ff3c",
   "metadata": {},
   "source": [
    "# Simple Promt in watsonx.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97c940d-e1a2-42c6-99b0-5210f685a002",
   "metadata": {},
   "source": [
    "In this notebook I will show how to perform  a simple query prompt from Jupyter!\n",
    "\n",
    "## Step 1- Libraries\n",
    "First, we load our libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea217c48-cf47-4919-86e4-dbfce947745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "import os, getpass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1574850-d533-408b-afdb-53d34a8bb090",
   "metadata": {},
   "source": [
    "## Step 2- Load our Credentials\n",
    "In order to use the Foundation Models we require load the credentials of IBM Cloud \n",
    "\n",
    "### Watsonx API connection\n",
    "This cell defines the credentials required to work with watsonx API for Foundation\n",
    "Model inferencing.\n",
    "\n",
    "**Action:** Provide the IBM Cloud user API key. For details, see\n",
    "[documentation](https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a47ef1d-0dea-4443-896f-4b1c69e27acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter your WML api key (hit enter):  ········\n"
     ]
    }
   ],
   "source": [
    "credentials = {\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
    "    \"apikey\": getpass.getpass(\"Please enter your WML api key (hit enter): \")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3afb077-438b-420f-be87-10623a05d298",
   "metadata": {},
   "source": [
    "Defining the project id\r\n",
    "The API requires project id that provides the context for the call. We will obtain the id from the project in which this notebook runs. Otherwise, please provide the project id.\r\n",
    "\r\n",
    "Hint: You can find the project_id as follows. Open the prompt lab in watsonx.ai. At the very top of the UI, there will be Projects / <project name> /. Click on the <project name> link. Then get the project_id from Project's Manage tab (Project -> Manage -> General -> Details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa8ea858-3206-4c97-8d86-fdebc82b9744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter your project_id (hit enter):  4c0dbedd-56ed-4eea-b36d-02be7323472a\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    project_id = os.environ[\"PROJECT_ID\"]\n",
    "except KeyError:\n",
    "    project_id = input(\"Please enter your project_id (hit enter): \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e63423-bc27-4a23-bc09-9067aef25eb2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"models\"></a>\n",
    "## Step 3 - Foundation Models on Watsonx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07053020-3c14-4643-b5fa-08afef9af62b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You need to specify `model_id` that will be used for inferencing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e92990-6109-4ec6-9371-252162fb818f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Action**: Use `FLAN_UL2` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a14b500-03ca-4bf0-803f-6921029e587a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1878b187-4e86-491a-a29a-16b044d3d9ae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_id = ModelTypes.FLAN_UL2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d46d7b7-8a38-4617-908b-bd899b3babe5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Step 4 -Defining the model parameters\n",
    "We need to provide a set of model parameters that will influence the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5450ff3-a076-45c8-85b0-2e45f1fff387",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watson_machine_learning.foundation_models.utils.enums import DecodingMethods\n",
    "\n",
    "parameters = {\n",
    "    GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n",
    "    GenParams.MIN_NEW_TOKENS: 1,\n",
    "    GenParams.MAX_NEW_TOKENS: 50\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efbf133-e8a2-4cc5-9ca1-a0677a92add2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Initialize the `Model` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97d789cd-1835-407b-8d84-05fd5800c91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell should never fail, and will produce no output\n",
    "import requests\n",
    "\n",
    "def getBearer(apikey):\n",
    "    form = {'apikey': apikey, 'grant_type': \"urn:ibm:params:oauth:grant-type:apikey\"}\n",
    "    print(\"About to create bearer\")\n",
    "#    print(form)\n",
    "    response = requests.post(\"https://iam.cloud.ibm.com/oidc/token\", data = form)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Bad response code retrieving token\")\n",
    "        raise Exception(\"Failed to get token, invalid status\")\n",
    "    json = response.json()\n",
    "    if not json:\n",
    "        print(\"Invalid/no JSON retrieving token\")\n",
    "        raise Exception(\"Failed to get token, invalid response\")\n",
    "    print(\"Bearer retrieved\")\n",
    "    return json.get(\"access_token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1a23da4-b939-443b-b4f5-f17a93c1a220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to create bearer\n",
      "Bearer retrieved\n"
     ]
    }
   ],
   "source": [
    "credentials[\"token\"] = getBearer(credentials[\"apikey\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "298c0fc7-6732-4fb4-9ac0-f893f88ec59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    model_id=model_id,\n",
    "    params=parameters,\n",
    "    credentials=credentials,\n",
    "    project_id=project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffa6b2e-1de5-488b-aa42-8c0d30ea3aa9",
   "metadata": {},
   "source": [
    "### Step 5 - Make the prompt to  `watsonx.ai` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae7b1568-4dd5-4fa2-97ff-6719a2272f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(lang, code):\n",
    "    prompt=f\"Respond only with code. Fix this {lang} code: \"+ f\"{code}\"\n",
    "    return prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d8e0722-01db-4a79-8341-164234f28f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_code='''prinf(\"Hello world)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93358e35-189b-4a17-9d87-2ce5b14ef9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text=make_prompt(\"python\",prompt_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9091b9f4-63a0-4aac-97f2-e294e01479d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Respond only with code. Fix this python code: prinf(\"Hello world)'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d37fe6b-0de1-42ca-823a-29633bb2c84f",
   "metadata": {},
   "source": [
    "### Generate a response\n",
    "**Note:** Execution of this cell could take few seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efa0478e-c275-4696-8c69-0c66ab061a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt_text):\n",
    "    results = []\n",
    "    results.append(model.generate_text(prompt=prompt_text))\n",
    "    return results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "481428c3-ee09-4aaf-9475-12aa8fc41653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(\"Hello world\")'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(prompt_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (GPT)",
   "language": "python",
   "name": "gpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
